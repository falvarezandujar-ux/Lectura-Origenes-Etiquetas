#!/usr/bin/env python3
"""
Analizador de Etiquetas de Aceite - Versi√≥n con OCR
Extrae informaci√≥n sobre el origen del aceite de etiquetas en PDF
Usa OCR para PDFs con texto en im√°genes
"""

import os
import re
import csv
from pathlib import Path
import pdfplumber
from PIL import Image
import pytesseract
import io
from typing import List, Tuple, Set

class AnalizadorEtiquetasAceiteOCR:
    """Analiza PDFs de etiquetas de aceite para extraer informaci√≥n de origen."""
    
    def __init__(self, carpeta_pdfs: str, archivo_salida: str = "origenes_aceite.csv"):
        """
        Inicializa el analizador.
        
        Args:
            carpeta_pdfs: Ruta a la carpeta con los PDFs
            archivo_salida: Nombre del archivo CSV de salida
        """
        self.carpeta_pdfs = Path(carpeta_pdfs)
        self.archivo_salida = archivo_salida
        
        # Patrones de b√∫squeda para detectar or√≠genes
        self.patrones_origen = [
            # Product of [Pa√≠s]
            r'Product\s+of\s+([A-Z][a-z]+(?:\s+[A-Z][a-z]+)?)',
            
            # Producto de [Pa√≠s]
            r'Producto\s+de\s+([A-Z√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+)?)',
            
            # Origen: [Pa√≠s/Pa√≠ses]
            r'Origen:\s*([A-Z√â√ç√ì√ö√ëa-z√°√©√≠√≥√∫√±\s,y]+)',
            
            # Patr√≥n espec√≠fico para Kroger: I: ITALY, S: SPAIN, etc.
            r'([A-Z]+):\s+(ITALY|SPAIN|PORTUGAL|GREECE|MOROCCO|TURKEY|TUNISIA|CHILE|ARGENTINA|FRANCE)',
            
            # Countries identified in the date code: [lista de pa√≠ses]
            r'[Cc]ountries?\s+identified\s+in\s+the\s+date\s+code[:\s]+([A-Z\s,;:\.0-9]+)',
            
            # Aceite de oliva de [Pa√≠s]
            r'[Aa]ceite\s+(?:de\s+oliva\s+)?de\s+([A-Z√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+)',
            
            # Mezcla de aceites de [pa√≠ses]
            r'[Mm]ezcla\s+de\s+aceites?\s+de\s+(?:la\s+)?(?:Uni√≥n\s+Europea|UE|([A-Z√â√ç√ì√ö√ëa-z√°√©√≠√≥√∫√±\s,y]+))',
            
            # Aceites de distintos or√≠genes / pa√≠ses
            r'[Aa]ceites?\s+de\s+(?:distintos\s+)?(?:or√≠genes?|pa√≠ses)\s*:?\s*([A-Z√â√ç√ì√ö√ëa-z√°√©√≠√≥√∫√±\s,y]+)?',
            
            # Made in / Elaborado en / Distributed by
            r'(?:Made\s+in|Elaborado\s+en|Envasado\s+en|Product\s+of)\s+([A-Z√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+)',
            
            # Aceite de oliva virgen extra espa√±ol
            r'[Aa]ceite\s+.*?\s+(espa√±ol|espa√±ola|italiano|italiana|griego|griega|tunecino|marroqu√≠|portugu√©s|portuguesa)',
            
            # UE / No UE
            r'(UE|Uni√≥n\s+Europea|No\s+UE|Fuera\s+de\s+la\s+UE|EU\s+Agriculture)',
            
            # Distributed by ... [pa√≠s]
            r'Distributed\s+by.*?(?:in|from)\s+([A-Z][a-z]+)',
        ]
        
        # Normalizaci√≥n de pa√≠ses
        self.normalizacion_paises = {
            'spain': 'Espa√±a',
            'espa√±a': 'Espa√±a',
            'espa√±ol': 'Espa√±a',
            'espa√±ola': 'Espa√±a',
            'italy': 'Italia',
            'italia': 'Italia',
            'italiano': 'Italia',
            'italiana': 'Italia',
            'greece': 'Grecia',
            'grecia': 'Grecia',
            'griego': 'Grecia',
            'griega': 'Grecia',
            'tunisia': 'T√∫nez',
            't√∫nez': 'T√∫nez',
            'tunecino': 'T√∫nez',
            'morocco': 'Marruecos',
            'marruecos': 'Marruecos',
            'marroqu√≠': 'Marruecos',
            'portugal': 'Portugal',
            'portugu√©s': 'Portugal',
            'portuguesa': 'Portugal',
            'turkey': 'Turqu√≠a',
            'turqu√≠a': 'Turqu√≠a',
            'turco': 'Turqu√≠a',
            'chile': 'Chile',
            'argentina': 'Argentina',
            'france': 'Francia',
            'francia': 'Francia',
            'ue': 'UE (Uni√≥n Europea)',
            'eu': 'UE (Uni√≥n Europea)',
            'uni√≥n europea': 'UE (Uni√≥n Europea)',
            'eu agriculture': 'UE (Uni√≥n Europea)',
            'no ue': 'No UE',
            'fuera de la ue': 'No UE',
        }
    
    def extraer_texto_pdf(self, ruta_pdf: Path) -> str:
        """
        Extrae el texto completo de un PDF usando extracci√≥n directa.
        
        Args:
            ruta_pdf: Ruta al archivo PDF
            
        Returns:
            Texto extra√≠do del PDF
        """
        texto_completo = ""
        try:
            with pdfplumber.open(ruta_pdf) as pdf:
                for pagina in pdf.pages:
                    texto = pagina.extract_text()
                    if texto:
                        texto_completo += texto + "\n"
        except Exception as e:
            print(f"‚ö†Ô∏è  Error al leer {ruta_pdf.name}: {str(e)}")
        
        return texto_completo
    
    def limpiar_texto_ocr(self, texto: str) -> str:
        """
        Limpia el texto OCR corrigiendo errores comunes.
        
        Args:
            texto: Texto con posibles errores de OCR
            
        Returns:
            Texto corregido
        """
        # Corregir | seguido de : como I: (com√∫n en OCR)
        texto = re.sub(r'\|:', 'I:', texto)
        
        # Corregir l: como I: cuando est√° en contexto de c√≥digos de pa√≠s
        texto = re.sub(r'(?<= )l:', 'I:', texto)
        
        return texto
    
    def extraer_texto_ocr(self, ruta_pdf: Path) -> str:
        """
        Extrae texto usando OCR de las im√°genes del PDF.
        
        Args:
            ruta_pdf: Ruta al archivo PDF
            
        Returns:
            Texto extra√≠do por OCR
        """
        texto_ocr = ""
        try:
            with pdfplumber.open(ruta_pdf) as pdf:
                for i, pagina in enumerate(pdf.pages):
                    # Convertir p√°gina a imagen
                    img = pagina.to_image(resolution=300)
                    pil_img = img.original
                    
                    # Aplicar OCR
                    texto = pytesseract.image_to_string(pil_img, lang='eng+spa')
                    if texto:
                        # Limpiar errores comunes de OCR
                        texto = self.limpiar_texto_ocr(texto)
                        texto_ocr += texto + "\n"
        except Exception as e:
            print(f"‚ö†Ô∏è  Error OCR en {ruta_pdf.name}: {str(e)}")
        
        return texto_ocr
    
    def detectar_origenes(self, texto: str) -> Set[str]:
        """
        Detecta los pa√≠ses de origen mencionados en el texto.
        
        Args:
            texto: Texto extra√≠do del PDF
            
        Returns:
            Conjunto de pa√≠ses detectados
        """
        origenes = set()
        
        # Lista de pa√≠ses v√°lidos en ingl√©s y espa√±ol
        paises_validos = {
            'spain', 'espa√±a', 'italy', 'italia', 'greece', 'grecia',
            'portugal', 'tunisia', 't√∫nez', 'morocco', 'marruecos',
            'turkey', 'turqu√≠a', 'chile', 'argentina', 'usa', 'eeuu',
            'france', 'francia', 'germany', 'alemania'
        }
        
        # Primero buscar el patr√≥n espec√≠fico de c√≥digos de pa√≠s (Kroger style)
        patron_codigos = r'([A-Z]+):\s+(ITALY|SPAIN|PORTUGAL|GREECE|MOROCCO|TURKEY|TUNISIA|CHILE|ARGENTINA|FRANCE)'
        matches_codigos = re.findall(patron_codigos, texto, re.IGNORECASE)
        for codigo, pais in matches_codigos:
            pais_limpio = pais.strip().lower()
            if pais_limpio in paises_validos or pais_limpio in self.normalizacion_paises:
                pais_normalizado = self.normalizacion_paises.get(pais_limpio, pais.strip().title())
                origenes.add(pais_normalizado)
        
        # Luego buscar otros patrones
        for patron in self.patrones_origen:
            matches = re.finditer(patron, texto, re.IGNORECASE | re.MULTILINE)
            for match in matches:
                # Determinar qu√© grupo captur√≥ el pa√≠s
                grupo_pais = None
                if match.lastindex and match.lastindex >= 1:
                    # Buscar el primer grupo no vac√≠o
                    for i in range(1, match.lastindex + 1):
                        if match.group(i) and match.group(i).strip():
                            grupo_pais = match.group(i)
                            break
                
                if grupo_pais:
                    # Limpiar y separar por comas, punto y coma o 'y'
                    paises_raw = re.split(r'[,;]|\sy\s|\sand\s', grupo_pais)
                    for pais in paises_raw:
                        # Quitar n√∫meros y limpiar
                        pais_limpio = re.sub(r'\d+', '', pais).strip().lower()
                        
                        # Filtrar solo si es un pa√≠s v√°lido o est√° en normalizaci√≥n
                        if pais_limpio in paises_validos or pais_limpio in self.normalizacion_paises:
                            # Normalizar
                            pais_normalizado = self.normalizacion_paises.get(
                                pais_limpio, 
                                pais.strip().title()
                            )
                            if len(pais_normalizado) > 2:
                                origenes.add(pais_normalizado)
        
        return origenes
    
    def extraer_codigo_archivo(self, nombre_archivo: str) -> str:
        """
        Extrae el c√≥digo de 6 cifras que empieza por 4 del nombre del archivo.
        
        Args:
            nombre_archivo: Nombre del archivo PDF
            
        Returns:
            C√≥digo extra√≠do o nombre completo si no se encuentra el patr√≥n
        """
        # Buscar patr√≥n: 6 d√≠gitos que empiezan por 4
        match = re.search(r'(4\d{5})', nombre_archivo)
        if match:
            return match.group(1)
        return nombre_archivo
    
    def procesar_carpeta(self) -> List[Tuple[str, str, str]]:
        """
        Procesa todos los PDFs de la carpeta.
        
        Returns:
            Lista de tuplas (nombre_archivo, c√≥digo, or√≠genes)
        """
        if not self.carpeta_pdfs.exists():
            print(f"‚ùå La carpeta {self.carpeta_pdfs} no existe.")
            return []
        
        resultados = []
        archivos_pdf = list(self.carpeta_pdfs.glob("*.pdf")) + list(self.carpeta_pdfs.glob("*.PDF"))
        
        if not archivos_pdf:
            print(f"‚ö†Ô∏è  No se encontraron archivos PDF en {self.carpeta_pdfs}")
            return []
        
        print(f"üìÇ Procesando {len(archivos_pdf)} archivos PDF...\n")
        
        for pdf_path in sorted(archivos_pdf):
            print(f"üîç Analizando: {pdf_path.name}")
            
            # Extraer texto normal
            texto_normal = self.extraer_texto_pdf(pdf_path)
            
            # Extraer texto con OCR
            print(f"   ‚Üí Aplicando OCR...")
            texto_ocr = self.extraer_texto_ocr(pdf_path)
            
            # Combinar ambos textos
            texto_completo = texto_normal + "\n" + texto_ocr
            
            # Detectar or√≠genes
            origenes = self.detectar_origenes(texto_completo)
            
            # Extraer c√≥digo
            codigo = self.extraer_codigo_archivo(pdf_path.name)
            
            # Formatear or√≠genes
            origenes_str = ", ".join(sorted(origenes)) if origenes else "No detectado"
            
            print(f"   ‚úì C√≥digo: {codigo}")
            print(f"   ‚úì Or√≠genes: {origenes_str}\n")
            
            resultados.append((pdf_path.name, codigo, origenes_str))
        
        return resultados
    
    def generar_csv(self, resultados: List[Tuple[str, str, str]]):
        """
        Genera el archivo CSV con los resultados.
        
        Args:
            resultados: Lista de tuplas con los datos procesados
        """
        if not resultados:
            print("‚ö†Ô∏è  No hay resultados para generar el CSV")
            return
        
        with open(self.archivo_salida, 'w', newline='', encoding='utf-8-sig') as archivo_csv:
            escritor = csv.writer(archivo_csv, delimiter=';')
            
            # Escribir encabezados
            escritor.writerow(['Nombre_Archivo', 'C√≥digo', 'Pa√≠ses_Origen'])
            
            # Escribir datos
            for fila in resultados:
                escritor.writerow(fila)
        
        print(f"‚úÖ Archivo CSV generado: {self.archivo_salida}")
        print(f"üìä Total de etiquetas procesadas: {len(resultados)}")
    
    def ejecutar(self):
        """Ejecuta el proceso completo de an√°lisis."""
        print("=" * 60)
        print("  ANALIZADOR DE ETIQUETAS DE ACEITE - ORIGEN (con OCR)")
        print("=" * 60)
        print()
        
        resultados = self.procesar_carpeta()
        self.generar_csv(resultados)
        
        print("\n" + "=" * 60)
        print("  PROCESO COMPLETADO")
        print("=" * 60)


def main():
    """Funci√≥n principal."""
    # Configuraci√≥n
    CARPETA_PDFS = "./etiquetas_pdf"  # Cambia esta ruta seg√∫n necesites
    ARCHIVO_SALIDA = "origenes_aceite.csv"
    
    # Crear el analizador y ejecutar
    analizador = AnalizadorEtiquetasAceiteOCR(CARPETA_PDFS, ARCHIVO_SALIDA)
    analizador.ejecutar()


if __name__ == "__main__":
    main()
